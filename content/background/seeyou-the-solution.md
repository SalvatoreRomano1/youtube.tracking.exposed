---
title: "How things can change, if many of us want it"
date: 2019-05-31T10:00:00+01:00
draft: false
---


This section should be written by a group of youtubers, not by me. Since these are technological rules that impact society (also called technopolitics), I compile a list that must serve as an inspiration, not as a list of requests.

## Content cannot be automatically moderated, never.
Content recognition algorithms might instead be used by the company, as long as the metadata assigned to the contents is accessible to both the content producer and consumer, and can be updated by the producer.

For example:
1. Anna publishes a self-defense video in which a fake attacker uses a plastic gun
2. The platform analyzes the video and attributes to the content two metadata "violence" and "weapons". These metadata would then be used to exclude the video from being monetized and to consider it harmful to minors.
3. Anna edits and removes these unjustified metadata and adds "self-defense" and “education”.

## An automatic recognition system can only exist if it empowers.
It should not be an imposition over individuals’ autonomy. Anna will be responsible for her statements. If she deceived the users with false metadata, only in this case, she could be sanctioned.

## The algorithms that manage notifications or any other kind of personalized suggestions must be under the control of consumers.
Thanks to the aforementioned metadata, notification criteria can be much more structured than the simple "follow a channel", because it is clear that a channel can produce different content. For example:
1. pewdipie is a channel with a large audience, famous for gaming videos.
2. pewdipie goes from just gaming, to gaming and entertaining videos
3. If you want to follow pewdipie, it's not a problem, it’s your choice
4. If you want to follow only pewdipie gaming videos, the system must provide the possibility to subscribe to the content in the most granular way possible.

If content producers can honestly describe what they have created, content filter and selection will be in the hands of the consumers.

(also: We don't need algorithms which learn from us and from social phenomenon. They are just an excuse to legitimize individual profiling).

## Advertisers must be able to add their messages in relation to the metadata that describe the videos’ content.
We must dismantle the justification of users’ profiling because, by its very nature, it will lead to a segmentation of perception that will damage our connected society.

# What the Youtuber Union (SeeYou) Wants to Do

1. We collectively analyze YouTube algorithm and collect evidence of algorithmic discrimination to ensure that the community of culture producers who rely on video platforms can be protected. Let's start with YouTube.
2. The youtubers union, SeeYou, wants to organize a coalition of content producers and rely on it to elaborate, with this community, a series of requests to Google.
3. The collection takes place through a browser extension, Chrome and Firefox, which could be promoted by youtubers to those who follow them. The collected data are not meant at profiling people, but instead at studying the platform.
4. Three different entities must work: the youtubers community that wants to be part of the union (who must express their needs and solicit the adoption of the extension), the pirate party (who organizes requests to Google and explain algorithm problems) and tracking.exposed (which produces data that can be used by the pirate party, youtubers and researchers).
5. YouTube emerges as a battleground, also because Google itself explicitly used the algorithm as a penalty and punishment system. We need to study this phenomenon and understand its political impact.
6. Technology stands as a "third party system, analyzing the algorithm, in the public interest". It is used by researchers, social scientists, and various types of analysts. The pirate party does what is called "ethical data reuse".
7. In this first phase the purposes are education and aggregation. Make the problem visible, develop ways to talk about the algorithmic repression of knowledge.
